{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215b1ed9",
   "metadata": {},
   "source": [
    "# Graph construction and feature extraction\n",
    "\n",
    "This notebook builds an undirected co-authorship graph from `trimmed_dataset.csv`.\n",
    "Nodes: authors (attribute: total_papers).\n",
    "Edges: co-authorship links (attribute: weight = number of joint publications).\n",
    "\n",
    "Outputs: graph object (NetworkX), node summary CSV, edge summary CSV, and a .png for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdee72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9560900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (166, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>categories</th>\n",
       "      <th>comments</th>\n",
       "      <th>doi</th>\n",
       "      <th>id</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>license</th>\n",
       "      <th>report-no</th>\n",
       "      <th>submitter</th>\n",
       "      <th>title</th>\n",
       "      <th>update_date</th>\n",
       "      <th>versions</th>\n",
       "      <th>author_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context. Swift data are revolutionising our ...</td>\n",
       "      <td>P.A. Evans (1), A.P. Beardmore (1), K.L. Page ...</td>\n",
       "      <td>[[\"Evans\", \"P. A.\", \"\"], [\"Beardmore\", \"A. P.\"...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>8 pages, 6 figures, Accepted for publication i...</td>\n",
       "      <td>10.1051/0004-6361:20077530</td>\n",
       "      <td>704.0128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kim Page</td>\n",
       "      <td>An online repository of Swift/XRT light curves...</td>\n",
       "      <td>2009-11-13</td>\n",
       "      <td>[{\"version\": \"v1\", \"created\": \"Mon, 2 Apr 2007...</td>\n",
       "      <td>['P. A. Evans', 'A. P. Beardmore', 'K. L. Page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The star HE 1305-0007 is a metal-poor double...</td>\n",
       "      <td>Wen-Yuan Cui (1,2,3), D. N. Cui (1), Y. S. Du ...</td>\n",
       "      <td>[[\"Cui\", \"Wen-Yuan\", \"\"], [\"Cui\", \"D. N.\", \"\"]...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>4 pages, 3 figures, paper accepted for publica...</td>\n",
       "      <td>10.1088/0256-307X/24/5/081</td>\n",
       "      <td>704.0576</td>\n",
       "      <td>Chin.Phys.Lett.24:1417-1421,2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wenyuan Cui</td>\n",
       "      <td>Neutron-Capture Elements in the Double-Enhance...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>[{\"version\": \"v1\", \"created\": \"Wed, 4 Apr 2007...</td>\n",
       "      <td>['Wen-Yuan Cui', 'D. N. Cui', 'Y. S. Du', 'B. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The search for MSSM Higgs bosons will be an ...</td>\n",
       "      <td>S. Gennai, S. Heinemeyer, A. Kalinowski, R. Ki...</td>\n",
       "      <td>[[\"Gennai\", \"S.\", \"\"], [\"Heinemeyer\", \"S.\", \"\"...</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>24 pages, 8 figures</td>\n",
       "      <td>10.1140/epjc/s10052-007-0398-0</td>\n",
       "      <td>704.0619</td>\n",
       "      <td>Eur.Phys.J.C52:383-395,2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DCPT/07/12, IPPP/07/06</td>\n",
       "      <td>Sven Heinemeyer</td>\n",
       "      <td>Search for Heavy Neutral MSSM Higgs Bosons wit...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[{\"version\": \"v1\", \"created\": \"Wed, 4 Apr 2007...</td>\n",
       "      <td>['S. Gennai', 'S. Heinemeyer', 'A. Kalinowski'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The blazar PKS0537-441 has been observed by ...</td>\n",
       "      <td>E. Pian (1), P. Romano (2,3), A. Treves (4), G...</td>\n",
       "      <td>[[\"Pian\", \"E.\", \"\"], [\"Romano\", \"P.\", \"\"], [\"T...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>24 pages, 7 figures, 3 tables, in press in the...</td>\n",
       "      <td>10.1086/518469</td>\n",
       "      <td>704.0958</td>\n",
       "      <td>Astrophys.J.664:106-116,2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elena Pian</td>\n",
       "      <td>Simultaneous Swift and REM monitoring of the b...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>[{\"version\": \"v1\", \"created\": \"Fri, 6 Apr 2007...</td>\n",
       "      <td>['E. Pian', 'P. Romano', 'A. Treves', 'G. Ghis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precise measurements of the single spin asym...</td>\n",
       "      <td>H. Okada, I. Alekseev, A. Bravar, G. Bunce, S....</td>\n",
       "      <td>[[\"Okada\", \"H.\", \"\"], [\"Alekseev\", \"I.\", \"\"], ...</td>\n",
       "      <td>hep-ex</td>\n",
       "      <td>4 pages</td>\n",
       "      <td>10.1063/1.2750871</td>\n",
       "      <td>704.1031</td>\n",
       "      <td>AIP Conf.Proc.915:681-684,2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hiromi Okada Dr.</td>\n",
       "      <td>Measurements of Single and Double Spin Asymmet...</td>\n",
       "      <td>2010-12-13</td>\n",
       "      <td>[{\"version\": \"v1\", \"created\": \"Sun, 8 Apr 2007...</td>\n",
       "      <td>['H. Okada', 'I. Alekseev', 'A. Bravar', 'G. B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0    Context. Swift data are revolutionising our ...   \n",
       "1    The star HE 1305-0007 is a metal-poor double...   \n",
       "2    The search for MSSM Higgs bosons will be an ...   \n",
       "3    The blazar PKS0537-441 has been observed by ...   \n",
       "4    Precise measurements of the single spin asym...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  P.A. Evans (1), A.P. Beardmore (1), K.L. Page ...   \n",
       "1  Wen-Yuan Cui (1,2,3), D. N. Cui (1), Y. S. Du ...   \n",
       "2  S. Gennai, S. Heinemeyer, A. Kalinowski, R. Ki...   \n",
       "3  E. Pian (1), P. Romano (2,3), A. Treves (4), G...   \n",
       "4  H. Okada, I. Alekseev, A. Bravar, G. Bunce, S....   \n",
       "\n",
       "                                      authors_parsed categories  \\\n",
       "0  [[\"Evans\", \"P. A.\", \"\"], [\"Beardmore\", \"A. P.\"...   astro-ph   \n",
       "1  [[\"Cui\", \"Wen-Yuan\", \"\"], [\"Cui\", \"D. N.\", \"\"]...   astro-ph   \n",
       "2  [[\"Gennai\", \"S.\", \"\"], [\"Heinemeyer\", \"S.\", \"\"...     hep-ph   \n",
       "3  [[\"Pian\", \"E.\", \"\"], [\"Romano\", \"P.\", \"\"], [\"T...   astro-ph   \n",
       "4  [[\"Okada\", \"H.\", \"\"], [\"Alekseev\", \"I.\", \"\"], ...     hep-ex   \n",
       "\n",
       "                                            comments  \\\n",
       "0  8 pages, 6 figures, Accepted for publication i...   \n",
       "1  4 pages, 3 figures, paper accepted for publica...   \n",
       "2                                24 pages, 8 figures   \n",
       "3  24 pages, 7 figures, 3 tables, in press in the...   \n",
       "4                                            4 pages   \n",
       "\n",
       "                              doi        id                       journal-ref  \\\n",
       "0      10.1051/0004-6361:20077530  704.0128                               NaN   \n",
       "1      10.1088/0256-307X/24/5/081  704.0576  Chin.Phys.Lett.24:1417-1421,2007   \n",
       "2  10.1140/epjc/s10052-007-0398-0  704.0619       Eur.Phys.J.C52:383-395,2007   \n",
       "3                  10.1086/518469  704.0958      Astrophys.J.664:106-116,2007   \n",
       "4               10.1063/1.2750871  704.1031    AIP Conf.Proc.915:681-684,2007   \n",
       "\n",
       "  license               report-no         submitter  \\\n",
       "0     NaN                     NaN          Kim Page   \n",
       "1     NaN                     NaN       Wenyuan Cui   \n",
       "2     NaN  DCPT/07/12, IPPP/07/06   Sven Heinemeyer   \n",
       "3     NaN                     NaN        Elena Pian   \n",
       "4     NaN                     NaN  Hiromi Okada Dr.   \n",
       "\n",
       "                                               title update_date  \\\n",
       "0  An online repository of Swift/XRT light curves...  2009-11-13   \n",
       "1  Neutron-Capture Elements in the Double-Enhance...  2009-06-23   \n",
       "2  Search for Heavy Neutral MSSM Higgs Bosons wit...  2008-11-26   \n",
       "3  Simultaneous Swift and REM monitoring of the b...  2009-06-23   \n",
       "4  Measurements of Single and Double Spin Asymmet...  2010-12-13   \n",
       "\n",
       "                                            versions  \\\n",
       "0  [{\"version\": \"v1\", \"created\": \"Mon, 2 Apr 2007...   \n",
       "1  [{\"version\": \"v1\", \"created\": \"Wed, 4 Apr 2007...   \n",
       "2  [{\"version\": \"v1\", \"created\": \"Wed, 4 Apr 2007...   \n",
       "3  [{\"version\": \"v1\", \"created\": \"Fri, 6 Apr 2007...   \n",
       "4  [{\"version\": \"v1\", \"created\": \"Sun, 8 Apr 2007...   \n",
       "\n",
       "                                         author_list  \n",
       "0  ['P. A. Evans', 'A. P. Beardmore', 'K. L. Page...  \n",
       "1  ['Wen-Yuan Cui', 'D. N. Cui', 'Y. S. Du', 'B. ...  \n",
       "2  ['S. Gennai', 'S. Heinemeyer', 'A. Kalinowski'...  \n",
       "3  ['E. Pian', 'P. Romano', 'A. Treves', 'G. Ghis...  \n",
       "4  ['H. Okada', 'I. Alekseev', 'A. Bravar', 'G. B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = '/mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/trimmed_dataset.csv'\n",
    "assert os.path.exists(csv_path), f'File not found: {csv_path}'\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded dataset with shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c43f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique authors found: 2792\n",
      "\n",
      "Sample of parsed author names (first 20):\n",
      "--\n",
      "A. A. Abdo\n",
      "A. A. Lednev\n",
      "A. A. Mozhegorov\n",
      "A. A. Petrov\n",
      "A. A. Wells\n",
      "A. Acha\n",
      "A. Akindinov\n",
      "A. Alici\n",
      "A. Alshino\n",
      "A. Amoroso\n",
      "A. Andronic\n",
      "A. Arbuzov\n",
      "A. Argan\n",
      "A. B. Gridnev\n",
      "A. B. Hill\n",
      "A. B. Kaidalov\n",
      "A. Badertscher\n",
      "A. Balanda\n",
      "A. Baran\n",
      "\n",
      "Potential issues in parsed names:\n",
      "Zhaxisangzhu\n",
      "Labaciren\n",
      "Krishichayan\n",
      "Risdiana\n",
      "--\n",
      "Danzengluobu\n",
      "Dinh-V-Trung\n"
     ]
    }
   ],
   "source": [
    "# Parse authors from authors_parsed column (structured format)\n",
    "def extract_authors_parsed(parsed_str):\n",
    "    \"\"\"Extract and normalize author names from authors_parsed column.\n",
    "    Expected format: List of [lastname, firstname, middle] entries\"\"\"\n",
    "    if pd.isna(parsed_str):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Parse the string representation of the list\n",
    "        author_list = ast.literal_eval(parsed_str)\n",
    "        \n",
    "        # Build full names from [lastname, firstname, middle] format\n",
    "        full_names = []\n",
    "        for author in author_list:\n",
    "            if len(author) >= 2:  # Must have at least lastname and firstname\n",
    "                # Combine: firstname middle lastname\n",
    "                first = author[1].strip()\n",
    "                last = author[0].strip()\n",
    "                middle = author[2].strip() if len(author) > 2 else \"\"\n",
    "                \n",
    "                # Build full name\n",
    "                if middle:\n",
    "                    full_name = f\"{first} {middle} {last}\"\n",
    "                else:\n",
    "                    full_name = f\"{first} {last}\"\n",
    "                \n",
    "                # Add normalized name if it looks valid\n",
    "                if full_name.strip():\n",
    "                    full_names.append(full_name.strip())\n",
    "        \n",
    "        return full_names\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Create both normalized and display versions of author names\n",
    "df['author_list'] = df['authors_parsed'].apply(extract_authors_parsed)\n",
    "\n",
    "# Validation: check the parsed authors\n",
    "all_authors = set()\n",
    "for authors in df['author_list']:\n",
    "    all_authors.update(authors)\n",
    "\n",
    "print(f\"\\nTotal unique authors found: {len(all_authors)}\")\n",
    "print(\"\\nSample of parsed author names (first 20):\")\n",
    "print('\\n'.join(sorted(list(all_authors))[:20]))\n",
    "\n",
    "# Basic validation of name formats\n",
    "malformed = []\n",
    "for name in all_authors:\n",
    "    parts = name.split()\n",
    "    if len(parts) < 2:  # Should have at least first and last name\n",
    "        malformed.append(name)\n",
    "    elif any(bool(re.search(r'\\d', part)) for part in parts):  # Check for digits\n",
    "        malformed.append(name)\n",
    "\n",
    "if malformed:\n",
    "    print(\"\\nPotential issues in parsed names:\")\n",
    "    print('\\n'.join(malformed))\n",
    "else:\n",
    "    print(\"\\nAll parsed names appear to be well-formed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fc4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique authors found: 2792\n",
      "\n",
      "Sample of parsed author names (first 20):\n",
      "--\n",
      "A. A. Abdo\n",
      "A. A. Lednev\n",
      "A. A. Mozhegorov\n",
      "A. A. Petrov\n",
      "A. A. Wells\n",
      "A. Acha\n",
      "A. Akindinov\n",
      "A. Alici\n",
      "A. Alshino\n",
      "A. Amoroso\n",
      "A. Andronic\n",
      "A. Arbuzov\n",
      "A. Argan\n",
      "A. B. Gridnev\n",
      "A. B. Hill\n",
      "A. B. Kaidalov\n",
      "A. Badertscher\n",
      "A. Balanda\n",
      "A. Baran\n",
      "\n",
      "Potential noise entries to review:\n",
      "Zhaxisangzhu\n",
      "Labaciren\n",
      "Krishichayan\n",
      "Risdiana\n",
      "--\n",
      "Danzengluobu\n",
      "Dinh-V-Trung\n"
     ]
    }
   ],
   "source": [
    "# Validation: check for any remaining potential noise in the parsed authors\n",
    "all_authors = set()\n",
    "for authors in df['author_list']:\n",
    "    all_authors.update(authors)\n",
    "\n",
    "print(f\"\\nTotal unique authors found: {len(all_authors)}\")\n",
    "print(\"\\nSample of parsed author names (first 20):\")\n",
    "print('\\n'.join(sorted(list(all_authors))[:20]))\n",
    "\n",
    "# Look for potential remaining noise (very short or suspicious patterns)\n",
    "suspicious = [name for name in all_authors if len(name.split()) < 2 or re.search(r'\\d', name)]\n",
    "if suspicious:\n",
    "    print(\"\\nPotential noise entries to review:\")\n",
    "    print('\\n'.join(suspicious))\n",
    "else:\n",
    "    print(\"\\nNo obvious noise entries found in the parsed authors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffaed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built: nodes = 2792 edges = 118561\n"
     ]
    }
   ],
   "source": [
    "# Build undirected co-authorship graph\n",
    "G = nx.Graph()\n",
    "author_papers = Counter()  # counts how many papers each author has\n",
    "edge_counts = Counter()    # counts joint publications between two authors\n",
    "\n",
    "for authors in df['author_list']:\n",
    "    # use unique authors for the paper (in case of duplicates)\n",
    "    unique_authors = list(dict.fromkeys([a for a in authors if a]))\n",
    "    # increment paper count for each author (one per paper)\n",
    "    for a in unique_authors:\n",
    "        author_papers[a] += 1\n",
    "    # add co-authorship edges for every pair in this paper\n",
    "    for a, b in itertools.combinations(sorted(unique_authors), 2):\n",
    "        edge_counts[(a, b)] += 1\n",
    "\n",
    "# Add nodes with total_papers attribute\n",
    "for author, count in author_papers.items():\n",
    "    G.add_node(author, total_papers=int(count))\n",
    "\n",
    "# Add edges with weight attribute (number of joint publications)\n",
    "for (a, b), w in edge_counts.items():\n",
    "    G.add_edge(a, b, weight=int(w))\n",
    "\n",
    "print('Graph built: nodes =', G.number_of_nodes(), 'edges =', G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c17c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 2792\n",
      "Total edges: 118561\n",
      "Density: 0.030430\n",
      "Average degree: 84.929\n"
     ]
    }
   ],
   "source": [
    "# Compute basic graph statistics\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "density = nx.density(G)\n",
    "degrees = dict(G.degree())\n",
    "avg_degree = sum(degrees.values()) / n_nodes if n_nodes > 0 else 0\n",
    "\n",
    "print(f'Total nodes: {n_nodes}')\n",
    "print(f'Total edges: {n_edges}')\n",
    "print(f'Density: {density:.6f}')\n",
    "print(f'Average degree: {avg_degree:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a76e1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 authors by total_papers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>total_papers</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N. Gehrels</td>\n",
       "      <td>35</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J. P. Osborne</td>\n",
       "      <td>22</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T. Suzuki</td>\n",
       "      <td>16</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D. N. Burrows</td>\n",
       "      <td>15</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S. Heinemeyer</td>\n",
       "      <td>14</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G. Weiglein</td>\n",
       "      <td>14</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P. Romano</td>\n",
       "      <td>12</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B. Zhang</td>\n",
       "      <td>11</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K. L. Page</td>\n",
       "      <td>11</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G. Chincarini</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author  total_papers  degree\n",
       "0     N. Gehrels            35     372\n",
       "1  J. P. Osborne            22     298\n",
       "2      T. Suzuki            16     299\n",
       "3  D. N. Burrows            15     193\n",
       "4  S. Heinemeyer            14     264\n",
       "5    G. Weiglein            14     263\n",
       "6      P. Romano            12     168\n",
       "7       B. Zhang            11     322\n",
       "8     K. L. Page            11     155\n",
       "9  G. Chincarini            10     201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 co-author pairs by joint publications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S. Heinemeyer</td>\n",
       "      <td>G. Weiglein</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D. N. Burrows</td>\n",
       "      <td>N. Gehrels</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J. P. Osborne</td>\n",
       "      <td>D. N. Burrows</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J. P. Osborne</td>\n",
       "      <td>N. Gehrels</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P. Romano</td>\n",
       "      <td>S. Campana</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P. Romano</td>\n",
       "      <td>G. Chincarini</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K. L. Page</td>\n",
       "      <td>J. P. Osborne</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G. Tagliaferri</td>\n",
       "      <td>G. Chincarini</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N. Gehrels</td>\n",
       "      <td>P. Romano</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S. Campana</td>\n",
       "      <td>G. Chincarini</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author_1       author_2  weight\n",
       "0   S. Heinemeyer    G. Weiglein      13\n",
       "1   D. N. Burrows     N. Gehrels      12\n",
       "2   J. P. Osborne  D. N. Burrows      10\n",
       "3   J. P. Osborne     N. Gehrels      10\n",
       "4       P. Romano     S. Campana       9\n",
       "5       P. Romano  G. Chincarini       9\n",
       "6      K. L. Page  J. P. Osborne       9\n",
       "7  G. Tagliaferri  G. Chincarini       9\n",
       "8      N. Gehrels      P. Romano       9\n",
       "9      S. Campana  G. Chincarini       8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create summary tables for documentation\n",
    "nodes_df = pd.DataFrame([{'author': n, 'total_papers': G.nodes[n].get('total_papers', 0), 'degree': G.degree(n)} for n in G.nodes()])\n",
    "nodes_df = nodes_df.sort_values(['total_papers','degree'], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "edges_df = pd.DataFrame([{'author_1': u, 'author_2': v, 'weight': d.get('weight',1)} for u,v,d in G.edges(data=True)])\n",
    "edges_df = edges_df.sort_values('weight', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print('Top 10 authors by total_papers:')\n",
    "display(nodes_df.head(10))\n",
    "\n",
    "print('Top 10 co-author pairs by joint publications:')\n",
    "display(edges_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7504b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/nodes_summary.csv /mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/edges_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save artifacts: summaries and graph file for visualization\n",
    "out_nodes = '/mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/nodes_summary.csv'\n",
    "out_edges = '/mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/edges_summary.csv'\n",
    "nodes_df.to_csv(out_nodes, index=False)\n",
    "edges_df.to_csv(out_edges, index=False)\n",
    "print('Saved:', out_nodes, out_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc25315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating layout...\n",
      "✓ Saved network visualization: /mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/coauthorship_network.png\n",
      "✓ Saved network visualization: /mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/coauthorship_network.png\n"
     ]
    }
   ],
   "source": [
    "# Create an enhanced network visualization\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Calculate node sizes based on degree centrality with better scaling\n",
    "node_degrees = dict(G.degree())\n",
    "max_degree = max(node_degrees.values())\n",
    "node_size = [((node_degrees[node] / max_degree) * 300 + 50) for node in G.nodes()]\n",
    "\n",
    "# Use the same layout parameters as the Louvain visualization for consistency\n",
    "print(\"Calculating layout...\")\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n",
    "\n",
    "# Draw edges with improved visibility (matching Louvain style)\n",
    "nx.draw_networkx_edges(G, pos, \n",
    "                      alpha=0.2,\n",
    "                      width=0.5,\n",
    "                      edge_color='gray')\n",
    "\n",
    "# Draw nodes with better visibility and styling\n",
    "nodes = nx.draw_networkx_nodes(G, pos,\n",
    "                              node_size=node_size,\n",
    "                              node_color='steelblue',\n",
    "                              alpha=0.8,\n",
    "                              edgecolors='black',\n",
    "                              linewidths=0.5)\n",
    "\n",
    "# Add labels for top authors with improved visibility (top 10 to match Louvain)\n",
    "top_authors = sorted(G.degree(), key=lambda x: x[1], reverse=True)[:10]\n",
    "labels = {node: node for node, degree in top_authors}\n",
    "nx.draw_networkx_labels(G, pos, labels, \n",
    "                       font_size=8,\n",
    "                       font_weight='bold',\n",
    "                       bbox=dict(facecolor='white', \n",
    "                               alpha=0.7,\n",
    "                               edgecolor='none',\n",
    "                               pad=0.5))\n",
    "\n",
    "# Add title and styling\n",
    "plt.title('Co-authorship Network\\n', \n",
    "         fontsize=16, \n",
    "         fontweight='bold')\n",
    "\n",
    "# Add legend-like text for interpretation\n",
    "plt.figtext(0.02, 0.02, \n",
    "            'Node size: Proportional to number of collaborations\\n' +\n",
    "            'Node color: Author (sized by collaboration count)\\n' +\n",
    "            'Edge: Represents co-authorship between authors',\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot with high resolution\n",
    "output_path = '/mnt/c/Users/Isaac/Documents/Visual Studio Code/GraphMining_Amalzen/outputs/graph_construction_and_feature_extraction/coauthorship_network.png'\n",
    "plt.savefig(output_path, \n",
    "            dpi=300, \n",
    "            bbox_inches='tight',\n",
    "            facecolor='white')\n",
    "plt.close()\n",
    "print(f'✓ Saved network visualization: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757c070",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Authors are parsed from the structured `authors_parsed` column which contains [lastname, firstname, middle] entries\n",
    "- Names are normalized to \"Firstname [Middle] Lastname\" format for consistency across all notebooks\n",
    "- This matches the format used in centrality and community detection analyses\n",
    "- The graph maintains the same author identities as other notebooks, enabling direct comparison of results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
